{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial: Causal Inference 07 - SHAP Interpretability\n",
        "\n",
        "Audience:\n",
        "- Learners who want to explain *why* uplift scores differ across users.\n",
        "\n",
        "Prerequisites:\n",
        "- Notebooks 01 to 06.\n",
        "\n",
        "Learning goals:\n",
        "- Build a SHAP-based interpretation workflow.\n",
        "- Identify which features drive uplift ranking.\n",
        "- Communicate model behavior in plain language.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outline\n",
        "\n",
        "1. Fit uplift learners and choose one score vector.\n",
        "2. Train a surrogate model to mimic uplift scores.\n",
        "3. Use SHAP values to rank feature importance.\n",
        "4. Turn feature importance into domain explanations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "project_root = Path.cwd().resolve()\n",
        "if not (project_root / \"src\").exists():\n",
        "    project_root = project_root.parent\n",
        "\n",
        "sys.path.insert(0, str(project_root / \"src\"))\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from causal_showcase.data import load_marketing_ab_data, train_test_split_prepared\n",
        "from causal_showcase.evaluation import qini_auc, qini_curve\n",
        "from causal_showcase.modeling import fit_meta_learners\n",
        "\n",
        "data_path = project_root / \"data\" / \"raw\" / \"marketing_ab.csv\"\n",
        "prepared = load_marketing_ab_data(data_path)\n",
        "train_data, test_data = train_test_split_prepared(prepared)\n",
        "\n",
        "learner_results = fit_meta_learners(train_data, test_data)\n",
        "\n",
        "rows = []\n",
        "for name, res in learner_results.items():\n",
        "    curve = qini_curve(test_data.outcome, test_data.treatment, res.uplift_scores)\n",
        "    rows.append({\"model\": name, \"qini_auc\": qini_auc(curve)})\n",
        "\n",
        "qini_df = pd.DataFrame(rows).sort_values(\"qini_auc\", ascending=False)\n",
        "best_model = str(qini_df.iloc[0][\"model\"])\n",
        "best_scores = learner_results[best_model].uplift_scores\n",
        "\n",
        "print(\"Selected model for interpretation:\", best_model)\n",
        "qini_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 - Train a surrogate model for explainability\n",
        "\n",
        "Why surrogate?\n",
        "- Some causal learners are harder to explain directly.\n",
        "- A surrogate model approximates uplift scores and gives stable SHAP values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "x_test = test_data.X.copy()\n",
        "surrogate = RandomForestRegressor(n_estimators=300, random_state=42)\n",
        "surrogate.fit(x_test, best_scores)\n",
        "\n",
        "surrogate_r2 = surrogate.score(x_test, best_scores)\n",
        "print(f\"Surrogate R^2 on uplift scores: {surrogate_r2:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 - Compute SHAP values and feature ranking\n",
        "\n",
        "SHAP (not \"SHAPE\") tells us how much each feature pushes predictions up or down.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "explainer = shap.TreeExplainer(surrogate)\n",
        "shap_values = explainer.shap_values(x_test)\n",
        "shap_array = np.asarray(shap_values)\n",
        "\n",
        "importance = np.abs(shap_array).mean(axis=0)\n",
        "importance_df = pd.DataFrame(\n",
        "    {\n",
        "        \"feature\": x_test.columns,\n",
        "        \"mean_abs_shap\": importance,\n",
        "    }\n",
        ").sort_values(\"mean_abs_shap\", ascending=False)\n",
        "\n",
        "importance_df.head(15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3 - Save SHAP summary plot\n",
        "\n",
        "This plot helps you visually explain feature influence patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "out_path = project_root / \"artifacts\" / \"figures\" / \"notebook_shap_summary.png\"\n",
        "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "shap.summary_plot(shap_array, x_test, show=False)\n",
        "plt.tight_layout()\n",
        "plt.savefig(out_path, dpi=160, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "\n",
        "print(f\"Saved SHAP summary to {out_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretation exercise\n",
        "\n",
        "Pick top 3 features and explain in plain language:\n",
        "- If feature value increases, does predicted uplift tend to increase or decrease?\n",
        "- Does this direction make business or domain sense?\n",
        "- What experiment would you run to validate this interpretation?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top3 = importance_df.head(3)[\"feature\"].tolist()\n",
        "print(\"Top 3 features:\", top3)\n",
        "print(\"Write your interpretation here for each feature.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
